{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "\n",
    "sys.path.append(\"tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data, test_classifier_scaling\n",
    "from auxiliary import computeFraction, evaluate_validate\n",
    "\n",
    "# enron_data = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 5600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'jeff.skilling@enron.com',\n",
       " 'exercised_stock_options': 19250000,\n",
       " 'expenses': 29336,\n",
       " 'from_messages': 108,\n",
       " 'from_poi_to_this_person': 88,\n",
       " 'from_this_person_to_poi': 30,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 1920000,\n",
       " 'other': 22122,\n",
       " 'poi': True,\n",
       " 'restricted_stock': 6843672,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 1111258,\n",
       " 'shared_receipt_with_poi': 2042,\n",
       " 'to_messages': 3627,\n",
       " 'total_payments': 8682716,\n",
       " 'total_stock_value': 26093672}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['SKILLING JEFFREY K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = data_dict['SKILLING JEFFREY K'].keys()\n",
    "features_list.remove('email_address')\n",
    "features_list.remove('poi')\n",
    "features_list = ['poi'] + features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers = ['TOTAL', 'THE TRAVEL AGENCY IN THE PARK']\n",
    "\n",
    "for point in outliers:\n",
    "    data_dict.pop(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "/// deleted below\n",
    "Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list)\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add features based on lecture 11 ud120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_dict = {}\n",
    "for name in my_dataset:\n",
    "\n",
    "    data_point = my_dataset[name]\n",
    "\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    submit_dict[name]={\"from_poi_to_this_person\":fraction_from_poi,\n",
    "                       \"from_this_person_to_poi\":fraction_to_poi}\n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 5600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'jeff.skilling@enron.com',\n",
       " 'exercised_stock_options': 19250000,\n",
       " 'expenses': 29336,\n",
       " 'fraction_from_poi': 0.0242624758753791,\n",
       " 'fraction_to_poi': 0.2777777777777778,\n",
       " 'from_messages': 108,\n",
       " 'from_poi_to_this_person': 88,\n",
       " 'from_this_person_to_poi': 30,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 1920000,\n",
       " 'other': 22122,\n",
       " 'poi': True,\n",
       " 'restricted_stock': 6843672,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 1111258,\n",
       " 'shared_receipt_with_poi': 2042,\n",
       " 'to_messages': 3627,\n",
       " 'total_payments': 8682716,\n",
       " 'total_stock_value': 26093672}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset['SKILLING JEFFREY K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>percentOfNaNs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>loan_advances</td>\n",
       "      <td>97.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>director_fees</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>restricted_stock_deferred</td>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deferral_payments</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>deferred_income</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>long_term_incentive</td>\n",
       "      <td>54.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bonus</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to_messages</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>from_this_person_to_poi</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>from_messages</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shared_receipt_with_poi</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from_poi_to_this_person</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>other</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>expenses</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>salary</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>restricted_stock</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>email_address</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>total_payments</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>total_stock_value</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fraction_from_poi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fraction_to_poi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  percentOfNaNs\n",
       "10              loan_advances           97.9\n",
       "13              director_fees           88.9\n",
       "8   restricted_stock_deferred           88.2\n",
       "1           deferral_payments           73.6\n",
       "15            deferred_income           66.7\n",
       "4         long_term_incentive           54.9\n",
       "14                      bonus           43.8\n",
       "0                 to_messages           40.3\n",
       "16    from_this_person_to_poi           40.3\n",
       "11              from_messages           40.3\n",
       "9     shared_receipt_with_poi           40.3\n",
       "6     from_poi_to_this_person           40.3\n",
       "12                      other           36.8\n",
       "2                    expenses           34.7\n",
       "19                     salary           34.7\n",
       "22    exercised_stock_options           29.9\n",
       "18           restricted_stock           24.3\n",
       "5               email_address           22.9\n",
       "20             total_payments           14.6\n",
       "17          total_stock_value           13.2\n",
       "7           fraction_from_poi            0.0\n",
       "3                         poi            0.0\n",
       "21            fraction_to_poi            0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count the NaNs and print percentage of NaNs for each feature\n",
    "\n",
    "my_df = pd.DataFrame(my_dataset).transpose()\n",
    "nan_counts_dict = {}\n",
    "for column in my_df.columns:\n",
    "    countit = (my_df[column]=='NaN').sum()\n",
    "    nan_counts_dict[column] = round(float(countit) / float(len(my_df[column])) * 100,1)\n",
    "nan_counts = pd.DataFrame(nan_counts_dict.items(), columns = ['feature', 'percentOfNaNs'])\n",
    "nan_counts = nan_counts.sort_values('percentOfNaNs', ascending=False)\n",
    "nan_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the percentage of NaNs, I will select the features with NaN percentage below 50%. I will exclude the features on which fraction_to_poi and fraction_from_poi are based, namely from_messages, from_poi_to_this_person, from_this_person_to_poi, to_messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bonus', 'exercised_stock_options', 'expenses', 'fraction_from_poi', 'fraction_to_poi', 'other', 'restricted_stock', 'salary', 'shared_receipt_with_poi', 'total_payments', 'total_stock_value']\n"
     ]
    }
   ],
   "source": [
    "exclude_features = ['from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'email_address', 'poi']\n",
    "for item in exclude_features:\n",
    "    if item in new_features:\n",
    "        new_features.remove(item)\n",
    "# new_features.remove(['from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'email_address', 'poi'])\n",
    "print new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'bonus', 'exercised_stock_options', 'expenses', 'fraction_from_poi', 'fraction_to_poi', 'other', 'restricted_stock', 'salary', 'shared_receipt_with_poi', 'total_payments', 'total_stock_value']\n"
     ]
    }
   ],
   "source": [
    "# include 'poi' feature to appear first in list\n",
    "new_features = ['poi'] + new_features\n",
    "print new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\tAccuracy: 0.33467\tPrecision: 0.14746\tRecall: 0.83450\tF1: 0.25064\tF2: 0.43198\n",
      "\tTotal predictions: 15000\tTrue positives: 1669\tFalse positives: 9649\tFalse negatives:  331\tTrue negatives: 3351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(gnb_clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\tAccuracy: 0.83673\tPrecision: 0.32420\tRecall: 0.20700\tF1: 0.25267\tF2: 0.22313\n",
      "\tTotal predictions: 15000\tTrue positives:  414\tFalse positives:  863\tFalse negatives: 1586\tTrue negatives: 12137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(gnb_clf, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "\tAccuracy: 0.79607\tPrecision: 0.22494\tRecall: 0.21650\tF1: 0.22064\tF2: 0.21814\n",
      "\tTotal predictions: 15000\tTrue positives:  433\tFalse positives: 1492\tFalse negatives: 1567\tTrue negatives: 11508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "\tAccuracy: 0.82973\tPrecision: 0.35766\tRecall: 0.34800\tF1: 0.35276\tF2: 0.34989\n",
      "\tTotal predictions: 15000\tTrue positives:  696\tFalse positives: 1250\tFalse negatives: 1304\tTrue negatives: 11750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_clf, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb_clf = AdaBoostClassifier(algorithm= 'SAMME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.84960\tPrecision: 0.41257\tRecall: 0.30200\tF1: 0.34873\tF2: 0.31910\n",
      "\tTotal predictions: 15000\tTrue positives:  604\tFalse positives:  860\tFalse negatives: 1396\tTrue negatives: 12140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(adb_clf, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA attempt below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "\n",
      "Explained Variance: 0.95\n",
      " Original Number of Dimensions: 11\n",
      " Final Dimensions: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "# data extraction using k_best features list\n",
    "# data = featureFormat(my_dataset, new_features, sort_keys = True)\n",
    "\n",
    "# data extraction using full features list, for pipe into PCA\n",
    "#data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "\n",
    "# labels2, features2 = targetFeatureSplit(data)\n",
    "\n",
    "## scale extracted features\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# trn = scaler.fit_transform(trn)\n",
    "\n",
    "# remove label from features_list\n",
    "features_for_pca = new_features[1:]\n",
    "\n",
    "# extract features\n",
    "data_for_pca = featureFormat(my_dataset, features_for_pca, sort_keys = True)\n",
    "\n",
    "# scale features\n",
    "scale_pca_data = preprocessing.MinMaxScaler().fit_transform(data_for_pca)\n",
    "\n",
    "# set up PCA to explain pre-selected % of variance (perc_var)\n",
    "perc_var = .95\n",
    "pca = PCA(n_components=perc_var)\n",
    "\n",
    "# fit and transform\n",
    "pca_transform = pca.fit_transform(scale_pca_data)\n",
    "\n",
    "# Starting features and ending components\n",
    "num_features = len(features_for_pca)\n",
    "components = pca_transform.shape[1]\n",
    "print 'PCA\\n'\n",
    "print 'Explained Variance: {0}\\n Original Number of Dimensions: {1}\\n Final Dimensions: {2}\\n'.format(perc_var,num_features,components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Initial Classifiers using PCA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "print 'Evaluate Initial Classifiers using PCA\\n'\n",
    "gnb_pipe = Pipeline(steps=[('pca', pca), ('gaussian', gnb_clf)])\n",
    "adb_pipe = Pipeline(steps=[('pca', pca), ('adaboost', adb_clf)])\n",
    "dt_pipe = Pipeline(steps = [('pca',pca),('decision_tree', dt_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf = Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('gaussian', GaussianNB())])\n",
      " Accuracy:0.906976744186\n",
      " Predicted Poi in test set:3.0\n",
      " Total Persons in test set:43\n",
      " Precision:0.666666666667\n",
      " Recall:0.4 \n",
      " F1 Score: 0.5 \n",
      "\n",
      "clf = Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None))])\n",
      " Accuracy:0.906976744186\n",
      " Predicted Poi in test set:3.0\n",
      " Total Persons in test set:43\n",
      " Precision:0.666666666667\n",
      " Recall:0.4 \n",
      " F1 Score: 0.5 \n",
      "\n",
      "clf = Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('decision_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))])\n",
      " Accuracy:0.860465116279\n",
      " Predicted Poi in test set:5.0\n",
      " Total Persons in test set:43\n",
      " Precision:0.4\n",
      " Recall:0.4 \n",
      " F1 Score: 0.4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the hand picked feature list called new_features\n",
    "\n",
    "evaluate_validate([gnb_pipe, adb_pipe, dt_pipe], my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf = Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('gaussian', GaussianNB())])\n",
      " Accuracy:0.883720930233\n",
      " Predicted Poi in test set:4.0\n",
      " Total Persons in test set:43\n",
      " Precision:0.5\n",
      " Recall:0.4 \n",
      " F1 Score: 0.444444444444 \n",
      "\n",
      "clf = Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None))])\n",
      " Accuracy:0.837209302326\n",
      " Predicted Poi in test set:6.0\n",
      " Total Persons in test set:43\n",
      " Precision:0.333333333333\n",
      " Recall:0.4 \n",
      " F1 Score: 0.363636363636 \n",
      "\n",
      "clf = Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('decision_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))])\n",
      " Accuracy:0.860465116279\n",
      " Predicted Poi in test set:5.0\n",
      " Total Persons in test set:43\n",
      " Precision:0.4\n",
      " Recall:0.4 \n",
      " F1 Score: 0.4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the long feature list\n",
    "\n",
    "evaluate_validate([gnb_pipe, adb_pipe, dt_pipe], my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using test_classifier_scaling for PCA scale_features=true for scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('gaussian', GaussianNB())])\n",
      "\tAccuracy: 0.82927\tPrecision: 0.36700\tRecall: 0.38700\tF1: 0.37673\tF2: 0.38283\n",
      "\tTotal predictions: 15000\tTrue positives:  774\tFalse positives: 1335\tFalse negatives: 1226\tTrue negatives: 11665\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3767339985397907"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_scaling(gnb_pipe, my_dataset, features_list, scale_features = True, std_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('gaussian', GaussianNB())])\n",
      "\tAccuracy: 0.87373\tPrecision: 0.55311\tRecall: 0.27600\tF1: 0.36825\tF2: 0.30673\n",
      "\tTotal predictions: 15000\tTrue positives:  552\tFalse positives:  446\tFalse negatives: 1448\tTrue negatives: 12554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(gnb_pipe, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None))])\n",
      "\tAccuracy: 0.82513\tPrecision: 0.26312\tRecall: 0.17300\tF1: 0.20875\tF2: 0.18572\n",
      "\tTotal predictions: 15000\tTrue positives:  346\tFalse positives:  969\tFalse negatives: 1654\tTrue negatives: 12031\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20874811463046758"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_scaling(adb_pipe, my_dataset, features_list, scale_features = True, std_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None))])\n",
      "\tAccuracy: 0.85333\tPrecision: 0.38962\tRecall: 0.17650\tF1: 0.24295\tF2: 0.19818\n",
      "\tTotal predictions: 15000\tTrue positives:  353\tFalse positives:  553\tFalse negatives: 1647\tTrue negatives: 12447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(adb_pipe, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('decision_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.79640\tPrecision: 0.25511\tRecall: 0.27450\tF1: 0.26445\tF2: 0.27039\n",
      "\tTotal predictions: 15000\tTrue positives:  549\tFalse positives: 1603\tFalse negatives: 1451\tTrue negatives: 11397\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26445086705202314"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_scaling(dt_pipe, my_dataset, features_list, scale_features = True, std_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('decision_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.77933\tPrecision: 0.19393\tRecall: 0.20750\tF1: 0.20048\tF2: 0.20464\n",
      "\tTotal predictions: 15000\tTrue positives:  415\tFalse positives: 1725\tFalse negatives: 1585\tTrue negatives: 11275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_pipe, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standard PCA with hand picked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('gaussian', GaussianNB())])\n",
      "\tAccuracy: 0.82593\tPrecision: 0.32769\tRecall: 0.29050\tF1: 0.30798\tF2: 0.29725\n",
      "\tTotal predictions: 15000\tTrue positives:  581\tFalse positives: 1192\tFalse negatives: 1419\tTrue negatives: 11808\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3079777365491651"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_scaling(gnb_pipe, my_dataset, new_features, scale_features = True, std_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('gaussian', GaussianNB())])\n",
      "\tAccuracy: 0.86847\tPrecision: 0.51235\tRecall: 0.28000\tF1: 0.36211\tF2: 0.30793\n",
      "\tTotal predictions: 15000\tTrue positives:  560\tFalse positives:  533\tFalse negatives: 1440\tTrue negatives: 12467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(gnb_pipe, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None))])\n",
      "\tAccuracy: 0.84240\tPrecision: 0.35601\tRecall: 0.22500\tF1: 0.27574\tF2: 0.24288\n",
      "\tTotal predictions: 15000\tTrue positives:  450\tFalse positives:  814\tFalse negatives: 1550\tTrue negatives: 12186\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2757352941176471"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_scaling(adb_pipe, my_dataset, new_features, scale_features = True, std_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None))])\n",
      "\tAccuracy: 0.85887\tPrecision: 0.41485\tRecall: 0.14250\tF1: 0.21213\tF2: 0.16404\n",
      "\tTotal predictions: 15000\tTrue positives:  285\tFalse positives:  402\tFalse negatives: 1715\tTrue negatives: 12598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(adb_pipe, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('decision_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.81147\tPrecision: 0.29785\tRecall: 0.30500\tF1: 0.30138\tF2: 0.30354\n",
      "\tTotal predictions: 15000\tTrue positives:  610\tFalse positives: 1438\tFalse negatives: 1390\tTrue negatives: 11562\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30138339920948615"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classifier_scaling(dt_pipe, my_dataset, new_features, scale_features = True, std_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('decision_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.77473\tPrecision: 0.14330\tRecall: 0.13850\tF1: 0.14086\tF2: 0.13943\n",
      "\tTotal predictions: 15000\tTrue positives:  277\tFalse positives: 1656\tFalse negatives: 1723\tTrue negatives: 11344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_pipe, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=12, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='random')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "data = featureFormat(my_dataset, new_features, sort_keys = True)\n",
    "\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "parameters = {'min_samples_split':[2,4,6,8,10,12,50],\n",
    "              'splitter': ('best','random'),\n",
    "              'max_depth':[None,2,4,6,8,10,15,20]\n",
    "              }\n",
    "clf_s = grid_search.GridSearchCV(dt_clf, parameters).fit(features, labels)\n",
    "print 'best estimator:'\n",
    "print clf_s.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_pipe2 = Pipeline(steps=[('pca',pca),('dt', clf_s.best_estimator_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=0.95, whiten=False)), ('dt', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=12, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='random'))])\n",
      "\tAccuracy: 0.87467\tPrecision: 0.66575\tRecall: 0.12050\tF1: 0.20406\tF2: 0.14410\n",
      "\tTotal predictions: 15000\tTrue positives:  241\tFalse positives:  121\tFalse negatives: 1759\tTrue negatives: 12879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_pipe2, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
