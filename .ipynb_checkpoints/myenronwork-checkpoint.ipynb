{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name evaluate_validate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-2fdef2b7252b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeatureFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetFeatureSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtester\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdump_classifier_and_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomputeFraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# enron_data = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name evaluate_validate"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "\n",
    "sys.path.append(\"tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "from auxiliary import computeFraction, evaluate_validate\n",
    "\n",
    "# enron_data = pickle.load(open(\"final_project_dataset.pkl\", \"r\"))\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 5600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'jeff.skilling@enron.com',\n",
       " 'exercised_stock_options': 19250000,\n",
       " 'expenses': 29336,\n",
       " 'from_messages': 108,\n",
       " 'from_poi_to_this_person': 88,\n",
       " 'from_this_person_to_poi': 30,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 1920000,\n",
       " 'other': 22122,\n",
       " 'poi': True,\n",
       " 'restricted_stock': 6843672,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 1111258,\n",
       " 'shared_receipt_with_poi': 2042,\n",
       " 'to_messages': 3627,\n",
       " 'total_payments': 8682716,\n",
       " 'total_stock_value': 26093672}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['SKILLING JEFFREY K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = data_dict['SKILLING JEFFREY K'].keys()\n",
    "features_list.remove('email_address')\n",
    "features_list.remove('poi')\n",
    "features_list = ['poi'] + features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers = ['TOTAL', 'THE TRAVEL AGENCY IN THE PARK']\n",
    "\n",
    "for point in outliers:\n",
    "    data_dict.pop(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "# data = featureFormat(my_dataset, features_list)\n",
    "# data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "# labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>percent_of_NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loan_advances</td>\n",
       "      <td>97.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>director_fees</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restricted_stock_deferred</td>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deferral_payments</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deferred_income</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>long_term_incentive</td>\n",
       "      <td>54.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonus</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from_poi_to_this_person</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>from_this_person_to_poi</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from_messages</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shared_receipt_with_poi</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>to_messages</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>other</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expenses</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>salary</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>restricted_stock</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>total_payments</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_stock_value</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>poi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  percent_of_NaN\n",
       "9               loan_advances            97.9\n",
       "3               director_fees            88.9\n",
       "14  restricted_stock_deferred            88.2\n",
       "1           deferral_payments            73.6\n",
       "2             deferred_income            66.7\n",
       "10        long_term_incentive            54.9\n",
       "0                       bonus            43.8\n",
       "7     from_poi_to_this_person            40.3\n",
       "8     from_this_person_to_poi            40.3\n",
       "6               from_messages            40.3\n",
       "16    shared_receipt_with_poi            40.3\n",
       "17                to_messages            40.3\n",
       "11                      other            36.8\n",
       "5                    expenses            34.7\n",
       "15                     salary            34.7\n",
       "4     exercised_stock_options            29.9\n",
       "13           restricted_stock            24.3\n",
       "18             total_payments            14.6\n",
       "19          total_stock_value            13.2\n",
       "12                        poi             0.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count the NaNs and print percentage of NaNs for each feature\n",
    "\n",
    "my_df = pd.DataFrame(my_dataset).transpose() # turn columns to rows\n",
    "# my_df = my_df.drop('email_address')\n",
    "nan_counts_dict = {}\n",
    "for column in my_df.columns:\n",
    "    my_df[column] = my_df[column].replace('NaN',np.nan)\n",
    "    nan_counts = my_df[column].isnull().sum()\n",
    "    nan_counts_dict[column] = round(float(nan_counts)/float(len(my_df[column])) * 100,1)\n",
    "df = pd.DataFrame(nan_counts_dict,index = ['percent_of_NaN']).transpose()\n",
    "df = df.drop('email_address')\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df = df.rename(columns = {'index':'feature'}).sort_values('percent_of_NaN', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add features based on lecture 11 ud120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_dict = {}\n",
    "for name in my_dataset:\n",
    "\n",
    "    data_point = my_dataset[name]\n",
    "\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    submit_dict[name]={\"from_poi_to_this_person\":fraction_from_poi,\n",
    "                       \"from_this_person_to_poi\":fraction_to_poi}\n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 5600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'jeff.skilling@enron.com',\n",
       " 'exercised_stock_options': 19250000,\n",
       " 'expenses': 29336,\n",
       " 'fraction_from_poi': 0.0242624758753791,\n",
       " 'fraction_to_poi': 0.2777777777777778,\n",
       " 'from_messages': 108,\n",
       " 'from_poi_to_this_person': 88,\n",
       " 'from_this_person_to_poi': 30,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 1920000,\n",
       " 'other': 22122,\n",
       " 'poi': True,\n",
       " 'restricted_stock': 6843672,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 1111258,\n",
       " 'shared_receipt_with_poi': 2042,\n",
       " 'to_messages': 3627,\n",
       " 'total_payments': 8682716,\n",
       " 'total_stock_value': 26093672}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset['SKILLING JEFFREY K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>percent_of_NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loan_advances</td>\n",
       "      <td>97.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>director_fees</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>restricted_stock_deferred</td>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deferral_payments</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deferred_income</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>long_term_incentive</td>\n",
       "      <td>54.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bonus</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>from_messages</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from_poi_to_this_person</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>from_this_person_to_poi</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>shared_receipt_with_poi</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>to_messages</td>\n",
       "      <td>40.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>other</td>\n",
       "      <td>36.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>expenses</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>salary</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exercised_stock_options</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restricted_stock</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>total_payments</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>total_stock_value</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fraction_to_poi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fraction_from_poi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>poi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  percent_of_NaN\n",
       "11              loan_advances            97.9\n",
       "3               director_fees            88.9\n",
       "16  restricted_stock_deferred            88.2\n",
       "1           deferral_payments            73.6\n",
       "2             deferred_income            66.7\n",
       "12        long_term_incentive            54.9\n",
       "0                       bonus            43.8\n",
       "8               from_messages            40.3\n",
       "9     from_poi_to_this_person            40.3\n",
       "10    from_this_person_to_poi            40.3\n",
       "18    shared_receipt_with_poi            40.3\n",
       "19                to_messages            40.3\n",
       "13                      other            36.8\n",
       "5                    expenses            34.7\n",
       "17                     salary            34.7\n",
       "4     exercised_stock_options            29.9\n",
       "15           restricted_stock            24.3\n",
       "20             total_payments            14.6\n",
       "21          total_stock_value            13.2\n",
       "7             fraction_to_poi             0.0\n",
       "6           fraction_from_poi             0.0\n",
       "14                        poi             0.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count the NaNs and print percentage of NaNs for each feature\n",
    "\n",
    "my_df = pd.DataFrame(my_dataset).transpose() # turn columns to rows\n",
    "nan_counts_dict = {}\n",
    "new_features = []\n",
    "for column in my_df.columns:\n",
    "    my_df[column] = my_df[column].replace('NaN',np.nan)\n",
    "    nan_counts = my_df[column].isnull().sum()\n",
    "    nan_counts_dict[column] = round(float(nan_counts)/float(len(my_df[column])) * 100,1)\n",
    "    if nan_counts_dict[column] < 50:\n",
    "        new_features.append(column)\n",
    "df = pd.DataFrame(nan_counts_dict,index = ['percent_of_NaN']).transpose() # turn columns to rows\n",
    "df = df.drop('email_address')\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df = df.rename(columns = {'index':'feature'}).sort_values('percent_of_NaN', ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the percentage of NaNs, I will select the features with NaN percentage below 50%. I will exclude the features on which fraction_to_poi and fraction_from_poi are based, namely from_messages, from_poi_to_this_person, from_this_person_to_poi, to_messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bonus', 'exercised_stock_options', 'expenses', 'fraction_from_poi', 'fraction_to_poi', 'other', 'restricted_stock', 'salary', 'shared_receipt_with_poi', 'total_payments', 'total_stock_value']\n"
     ]
    }
   ],
   "source": [
    "exclude_features = ['from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'email_address', 'poi']\n",
    "for item in exclude_features:\n",
    "    if item in new_features:\n",
    "        new_features.remove(item)\n",
    "# new_features.remove(['from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'to_messages', 'email_address', 'poi'])\n",
    "print new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'bonus', 'exercised_stock_options', 'expenses', 'fraction_from_poi', 'fraction_to_poi', 'other', 'restricted_stock', 'salary', 'shared_receipt_with_poi', 'total_payments', 'total_stock_value']\n"
     ]
    }
   ],
   "source": [
    "# include 'poi' feature to appear first in list\n",
    "new_features = ['poi'] + new_features\n",
    "print new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\tAccuracy: 0.33467\tPrecision: 0.14746\tRecall: 0.83450\tF1: 0.25064\tF2: 0.43198\n",
      "\tTotal predictions: 15000\tTrue positives: 1669\tFalse positives: 9649\tFalse negatives:  331\tTrue negatives: 3351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(gnb_clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "\tAccuracy: 0.83673\tPrecision: 0.32420\tRecall: 0.20700\tF1: 0.25267\tF2: 0.22313\n",
      "\tTotal predictions: 15000\tTrue positives:  414\tFalse positives:  863\tFalse negatives: 1586\tTrue negatives: 12137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(gnb_clf, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "\tAccuracy: 0.79653\tPrecision: 0.22661\tRecall: 0.21800\tF1: 0.22222\tF2: 0.21967\n",
      "\tTotal predictions: 15000\tTrue positives:  436\tFalse positives: 1488\tFalse negatives: 1564\tTrue negatives: 11512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "\tAccuracy: 0.82927\tPrecision: 0.35549\tRecall: 0.34500\tF1: 0.35016\tF2: 0.34705\n",
      "\tTotal predictions: 15000\tTrue positives:  690\tFalse positives: 1251\tFalse negatives: 1310\tTrue negatives: 11749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_clf, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb_clf = AdaBoostClassifier(algorithm= 'SAMME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.84960\tPrecision: 0.41257\tRecall: 0.30200\tF1: 0.34873\tF2: 0.31910\n",
      "\tTotal predictions: 15000\tTrue positives:  604\tFalse positives:  860\tFalse negatives: 1396\tTrue negatives: 12140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(adb_clf, my_dataset, new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA attempt below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "\n",
      "Explained Variance: 0.95\n",
      " Original Number of Dimensions: 11\n",
      " Final Dimensions: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "# data extraction using k_best features list\n",
    "# data = featureFormat(my_dataset, new_features, sort_keys = True)\n",
    "\n",
    "# data extraction using full features list, for pipe into PCA\n",
    "#data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "\n",
    "# labels2, features2 = targetFeatureSplit(data)\n",
    "\n",
    "## scale extracted features\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# trn = scaler.fit_transform(trn)\n",
    "\n",
    "# remove label from features_list\n",
    "features_for_pca = new_features[1:]\n",
    "\n",
    "# extract features\n",
    "data_for_pca = featureFormat(my_dataset, features_for_pca, sort_keys = True)\n",
    "\n",
    "# scale features\n",
    "scale_pca_data = preprocessing.MinMaxScaler().fit_transform(data_for_pca)\n",
    "\n",
    "# set up PCA to explain pre-selected % of variance (perc_var)\n",
    "perc_var = .95\n",
    "pca = PCA(n_components=perc_var)\n",
    "\n",
    "# fit and transform\n",
    "pca_transform = pca.fit_transform(scale_pca_data)\n",
    "\n",
    "# Starting features and ending components\n",
    "num_features = len(features_for_pca)\n",
    "components = pca_transform.shape[1]\n",
    "print 'PCA\\n'\n",
    "print 'Explained Variance: {0}\\n Original Number of Dimensions: {1}\\n Final Dimensions: {2}\\n'.format(perc_var,num_features,components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "print features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Initial Classifiers using PCA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "print 'Evaluate Initial Classifiers using PCA\\n'\n",
    "gnb_pipe = Pipeline(steps=[('pca', pca), ('gaussian', gnb_clf)])\n",
    "adb_pipe = Pipeline(steps=[('pca', pca), ('adaboost', adb_clf)])\n",
    "dt_pipe = Pipeline(steps = [('pca',pca),('decision_tree', dt_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name evaluate_validate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-a4a533938206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name evaluate_validate"
     ]
    }
   ],
   "source": [
    "from auxiliary import evaluate_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=8, whiten=False)), ('gaussian', GaussianNB())])\n",
      "\tAccuracy: 0.85053\tPrecision: 0.42568\tRecall: 0.34650\tF1: 0.38203\tF2: 0.35989\n",
      "\tTotal predictions: 15000\tTrue positives:  693\tFalse positives:  935\tFalse negatives: 1307\tTrue negatives: 12065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(gnb_pipe, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=8, whiten=False)), ('adaboost', AdaBoostClassifier(algorithm='SAMME', base_estimator=None, learning_rate=1.0,\n",
      "          n_estimators=50, random_state=None))])\n",
      "\tAccuracy: 0.83433\tPrecision: 0.25280\tRecall: 0.12400\tF1: 0.16639\tF2: 0.13807\n",
      "\tTotal predictions: 15000\tTrue positives:  248\tFalse positives:  733\tFalse negatives: 1752\tTrue negatives: 12267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(adb_pipe, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=8, whiten=False)), ('decision_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.80180\tPrecision: 0.26140\tRecall: 0.26650\tF1: 0.26393\tF2: 0.26546\n",
      "\tTotal predictions: 15000\tTrue positives:  533\tFalse positives: 1506\tFalse negatives: 1467\tTrue negatives: 11494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_pipe, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune Classifiers\n",
      "\n",
      "Decision tree tuning\n",
      " Steps: [('reduce_dim', PCA(copy=True, n_components=None, whiten=False)), ('dec_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))]\n",
      ", Best Parameters: {'dec_tree__max_depth': 2, 'dec_tree__criterion': 'gini', 'dec_tree__min_samples_leaf': 1, 'reduce_dim__n_components': 0.95, 'dec_tree__min_samples_split': 8}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation\n",
    "print \"Tune Classifiers\\n\"\n",
    "\n",
    "## Tune decision tree via gridsearch\n",
    "\n",
    "# Set up cross validator (will be used for tuning all classifiers)\n",
    "cv = cross_validation.StratifiedShuffleSplit(labels,\n",
    "                                            n_iter = 10,\n",
    "                                             random_state = 42)\n",
    "# set up estimator and pipeline, using PCA for feature selection\n",
    "estimators = [('reduce_dim', PCA()),('dec_tree',dt_clf)]\n",
    "dtclf = Pipeline(estimators)\n",
    "\n",
    "# set up paramaters dictionary\n",
    "dt_params = dict(reduce_dim__n_components=[perc_var],\n",
    "              dec_tree__criterion=(\"gini\",\"entropy\"),\n",
    "                  dec_tree__min_samples_split=[1,2,4,8,16,32],\n",
    "                   dec_tree__min_samples_leaf=[1,2,4,8,16,32],\n",
    "                   dec_tree__max_depth=[None,1,2,4,8,16,32])\n",
    "\n",
    "# set up gridsearch\n",
    "dt_grid_search = GridSearchCV(dtclf, param_grid = dt_params,\n",
    "                          scoring = 'f1', cv =cv)\n",
    "\n",
    "# pass data into into the gridsearch via fit\n",
    "dt_grid_search.fit(features, labels)\n",
    "\n",
    "print 'Decision tree tuning\\n Steps: {0}\\n, Best Parameters: {1}\\n '.format(dtclf.steps,dt_grid_search.best_params_,dt_grid_search.best_score_)\n",
    "# print sep2\n",
    "# pick a winner\n",
    "best_dtclf = dt_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_dt_params = DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
    "#                                         max_depth=2, min_samples_leaf=1, min_samples_split=8,\n",
    "#                                         splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_pipe2 = Pipeline(steps=[('pca',pca),('dt',best_dtclf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(copy=True, n_components=8, whiten=False)), ('dt', Pipeline(steps=[('reduce_dim', PCA(copy=True, n_components=0.95, whiten=False)), ('dec_tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best'))]))])\n",
      "\tAccuracy: 0.86533\tPrecision: 0.48371\tRecall: 0.14850\tF1: 0.22724\tF2: 0.17239\n",
      "\tTotal predictions: 15000\tTrue positives:  297\tFalse positives:  317\tFalse negatives: 1703\tTrue negatives: 12683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(dt_pipe2, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
